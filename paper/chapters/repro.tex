Since the research by Franz et al. itself uncovers instabilities in the usage of \ac{VQ-DQN}, the aim of reproducing the exact same results presented here, even with the usage of our reproducibility package, is limited. 
However, the two combined realms of \ac{RL}\autocite{rlrepro} and quantum computing\autocite{quantumrepro} have their own issues with reproducibility, even considered separately. 
So it lies in the nature of the topic that it is hard to define exact reproducibility criterias.
Our data is not the same data that Franz et al. or Lockwood and Si or Skolik et al. are able to aquire and further trainings of the agents, for example during the usage of our package, will produce different validation returns.


Our reproducibility package consists of three different stages: The first one is responsible for the training, the second one evaluates the data and generates a figure similar to Figure \ref{results} and the third one produces the paper. 

We decide to use different base images for a docker container based on the availability of a GPU. 
The GPU container has optimizations for the usage of one and the user can configure the container based on the own hardware. 

Another limitation lies in the hardware requirements for training. 
Our results are produced with a setup containing two AMD EPYC 7662 processors with 64 cores as CPUs, NVIDIA A100 SXM4 40 GB as GPU and 1 TiB of RAM and one run takes approximately one hour. 
Such a setup is not available for everyone who may want to reproduce a part of the experiments like evaluating the data. 
So we decide to skip the training and deliver our own data with our package, so it is possible to reconstruct the remaining part without meeting our hardware requirements. 

